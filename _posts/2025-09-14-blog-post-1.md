---
title: 'Anatomy of a Lock-Free Algorithm'
date: 2025-09-14
permalink: /posts/anatomy-of-a-lock-free-algorithm/
tags:
  - lock free data structures
  - graph algorithms
---

In this post, I'll describe lock-free implementations of 2 graph algorithms: (i) shortest path (ii) variable length
recursive join queries. This is the first part of two blog posts and is meant to be companion to my [VLDB '25 paper](https://arxiv.org/abs/2508.19379)
on parallelizing recursive queries in graph databases. The paper focuses more on efficient scheduling policies at the database physical operator level.
But we did not really get a chance to describe _how we parallelize the graph algorithms itself_ (section 4.2 in the paper provides some details).

// add a table right in the beginning to convey the importance / significance of work

Since *most* people don't have a background in graph database algorithms or what "lock-free" even means, I have a background section
on this. The two algorithms I describe here are on the opposite end of the spectrum. The (unweighted) shortest path query returning only
the path lengths is relatively easy in terms of what we need to keep track of and how to parallelize. The variable length path query (walk semantics) returning paths
is the most expensive (compute & memory wise) and complicated query you could ask a graph database to execute. At the end I also have a section
on what challenges we faced while running these queries, and how beneficial lock-free algorithms really are in practice. 


# Table of Contents
1. [Background](#Background)
2. [Shortest Path](#Shortest Path)
3. [Variable Length Path](#Variable Length Path)
4. [So,what's the catch?](#So,what's the catch?)


## Background

It's 2025, and most graph databases now support Cypher as a query language (finally some consolidation here).
Expressing many-to-many joins (queries with long join query patterns) or recursive queries in Cypher is way more intuitive.
When I say "recursive queries" here, I am referring to queries that involve repeated number of joins until a condition is satisfied.
The condition can be for example, encountering a particular node / row while (shortest path) or reaching a particular join depth (variable length).
In Cypher, if you wanted to write the unweighted shortest path query, and return the path length, this would be the syntax:

```sql
MATCH p = (a:Person)-[r:Knows* SHORTEST 1..30]->(b:Person)
WHERE a.name = 'Alice' AND b.name = 'Bob'  
RETURN length(p)
```

The above query would take the node 'Alice', explore who Alice knows (1 join) then explore their neighbours (2 joins) and keep
going until we hit 'Bob'. We "recursively" keep exploring until we either hit our destination or we hit the upper bound 
(specified after the **SHORTEST** keyword).

```sql
MATCH p = (a:Person)-[r:Knows* 1..10]->(b:Person)    
WHERE a.name = 'Alice' AND b.name = 'Bob'  
RETURN length(p)
```

This query is a bit different, as it does not have the SHORTEST keyword, it will compute all paths even if 'Bob' is encountered 
once. It's the (dreaded) variable length recursive join. There are different semantics for this query (ACYCLIC, TRAIL, SIMPLE) which
I'll explain next. The key difference to note here is the stopping condition of variable length query is hitting the upper bound 
specified, and depending on the semantics the query engine may have to keep track of cycles, which is not the case for the
shortest path query.

Let's take the following graph as an example (we'll keep using this as a running example):

<figure>
  <img src="/images/graph.png" alt="Description" style="width: 50%;" />
  <figcaption style="text-align: left;">Example Graph</figcaption>
</figure>

If a user ran the **SHORTEST** path query from node (1) to node (4), the result would return the path:
(1)-[e1]->(2)-[e3]->(4). If we need all the shortest paths, we could specify **ALL SHORTEST** in our query
and get back (1)-[e2]->(3)-[e4]->(4) as well. 

Now if we ran the variable length kleene star query between (1) and (4), notice that we have a cycle in our graph.
Based on which semantic is followed, the path to be returned would vary:

- ACYCLIC: no node and edge can be repeated 
- TRAIL: no edge can be repeated
- SIMPLE: no limitation on repeating nodes or edges

So, with **SIMPLE** var-len join, we would return (1)-[e1]->(2)-[e3]->(4), (1)-[e1]->(2)-[e5]->(1)-[e1]->(2)-[e3]->(4)
and keep going through this cycle until the upper bound for exploration has been reached.  
For **TRAIL** however, the rules change because (1)-[e1]->(2)-[e5]->(1)-[e1]->(2)-[e3]->(4) repeating edges ([e1] edge).
A valid path would be (1)-[e1]->(2)-[e5]->(1)-[e2]->(3)-[e4]->(4) where we did not repeat any edge, but the node (1) did get repeated.
The **ACYCLIC** semantic is the simplest that restricts repeating edges and nodes, it would eliminate both the above paths 
and just return (1)-[e1]->(2)-[e3]->(4) and (1)-[e2]->(3)-[e4]->(4).  

Now that we have the background about all the different recursive joins, in the following
sections I'll explain our implementation for the lock-free: (i) the shortest path query (returning path length) - 
the easiest algorithm to implement and parallelize and, (ii) the variable length path query with SIMPLE path semantics
(returning paths) - the hardest query to parallelize and get good performance on. 

## Shortest Path

The query we're trying to parallelize here:

```sql
MATCH p = (a:Person)-[r:Knows* SHORTEST 1..30]->(b:Person)
WHERE a.name = 'Alice' AND b.name = 'Bob'  
RETURN length(p)
```

Since this is the unweighted shortest path, the algorithm we have to run is the classic 
breadth first search. Usually, when we run BFS you would use a queue, keep dequeing nodes from the head
and enqueue neighbours at the end of the queue. For parallel BFS, there's two problems with this approach:
(i) in terms of performance, a concurrent thread-safe queue does not provide much speedup gains, 
(ii) we would run into a potential race condition if we use a single queue for parallel BFS.

// add the diagram + initial queue with single source node

Consider the above graph, the query starts to perform BFS from the source (1). First we would dequeue
(1) (by Thread 1) from the queue and need to add its neighbours (2), (3) and (4) into the queue. Additionally, we have
other Threads trying to dequeue from the head of queue. As soon as Thread 1 queue's (2) into the queue, Thread 2 will dequeue
(2) and try to explore its neighbours. This is the race condition would occur, if Thread 2 were to encounter the node (4)
before Thread 1 gets to 


## Variable Length Path


## So,what's the catch?



